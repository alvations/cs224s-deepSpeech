deepdive {

  # #############
  # CONFIGURATION
  # #############
  db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}  #"
    user: ${PGUSER}
    password: ${PGPASSWORD}
  }

  ######################### EVALUATION CONFIG #################

  # ###########
  # PIPELINES
  # ###########
  pipeline.run: "evaluation"

  # All we need is just to run "bash preprocess/import... then run"
  pipeline.pipelines.evaluation: [
    "ext_output_bestpath",
  ]

  # ##########
  # Extractors
  # ##########
  extraction.extractors {

    ############# TSV ###########
    ext_output_bestpath {
      style: "plpy_extractor"
      input: """
        SELECT    c.lattice_id AS lattice_id,
                  ARRAY_AGG(c.starts ORDER BY starts, ends)  AS starts,
                  ARRAY_AGG(c.ends   ORDER BY starts, ends)  AS ends,
                  ARRAY_AGG(c.word   ORDER BY starts, ends)  AS candidates,
                  ARRAY_AGG(c.candidate_id ORDER BY starts, ends) AS candidate_ids,
                  ARRAY_AGG(c.expectation ORDER BY starts, ends) AS expectations
        FROM      candidate_is_true_inference  c
        GROUP BY  c.lattice_id;
      """ # small dataset...
      udf: ${APP_HOME}"/udf/ext_output_bestpath.py"
      # udf: util/extractor_input_writer.py /tmp/deepspeech-sample-supervision.tsv
      output_relation: "output_bestpath"
      before: ${APP_HOME}"/udf/before/clear_table.sh output_bestpath"
      parallelism: ${PARALLELISM}
      input_batch_size: 1000
    }

  }

}

