deepdive {

  # #############
  # CONFIGURATION
  # #############
  db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}  #"
    user: ${PGUSER}
    password: ${PGPASSWORD}
  }

  sampler.sampler_cmd: "util/sampler-dw-linux gibbs"
  sampler.sampler_args: "-l 1000 -s 1 -i 1000 -a 0.01"
  # sampler.sampler_args: "-l 300 -s 1 -i 300 -a 0.1 -d 0.99"

  # pipeline.relearn_from: "/lfs/madmax2/0/zifei/deepdive/out/2014-04-28T152335/"

  # ###########
  # CALIBRATION
  # ###########
  # calibration.holdout_fraction: 0.25

  calibration.holdout_query: """
    INSERT INTO dd_graph_variables_holdout(variable_id) 
      SELECT id FROM candidate, lattices_holdout s
      WHERE candidate.lattice_id = s.lattice_id;
     """

  # ##############
  # VARIABLES
  # ##############
  schema.variables {
    candidate.is_true: Boolean
  }

  # ###########
  # PIPELINES
  # ###########
  pipeline.run: "all"

  # All we need is just to run "bash preprocess/import... then run"
  pipeline.pipelines.all: [
    "ext_sample", 
    # "ext_runall",

    "ext_prepare_variables",

    ############## DANGER #############
    
    ####### "ext_cand_2gram",  # only ONCE

    "ext_supervision",    # only once
    "ext_use_supervision",

    ### Rules
    "rule_cand_1gram",
    "rule_cand_1gram_nonexist",
    "rule_cand_2gram",
    "rule_cand_2gram_nonexist",
    "rule_confirm",
    "rule_silence",
    "rule_startend",
  ]


  # ##########
  # Extractors
  # ##########
  extraction.extractors {

    ext_sample {
      style: "sql_extractor"
      sql: """
        TRUNCATE lattices;

        INSERT INTO lattices
        SELECT lattice_id
        from transcript order by random() 
        limit 1000;

        TRUNCATE candidate;

        INSERT INTO candidate
        SELECT  c.* 
        FROM    candidate_all c, lattices l
        WHERE   c.lattice_id = l.lattice_id;

        ANALYZE candidate;
      """
    }
    ext_runall {
      style: "sql_extractor"
      sql: """
        TRUNCATE lattices;

        INSERT INTO lattices
        SELECT distinct lattice_id
        FROM transcript_array;

        ANALYZE lattices;

        TRUNCATE candidate;

        INSERT INTO candidate
        SELECT  * 
        FROM    candidate_all;

        ANALYZE candidate;
      """
    }

    # Prepare candidate table and holdout table
    ext_prepare_variables {
      style: "sql_extractor"
      dependencies: ["ext_sample", "ext_runall"]
      sql: """
        TRUNCATE lattices_holdout;

        INSERT INTO lattices_holdout
        SELECT * FROM lattices 
        WHERE random() < 0.5;

        ANALYZE lattices_holdout;
      """
    }

    ############# PLPY ###########
    # ext_supervision {
    #   dependencies: ["ext_sample", "ext_runall"]
    #   style: "plpy_extractor"
    #   input: """
    #     SELECT    c.lattice_id AS lattice_id,
    #               ARRAY_AGG(c.starts ORDER BY starts, ends)  AS starts,
    #               ARRAY_AGG(c.ends   ORDER BY starts, ends)  AS ends,
    #               ARRAY_AGG(c.word   ORDER BY starts, ends)  AS candidates,
    #               ARRAY_AGG(c.candidate_id ORDER BY starts, ends) AS candidate_ids,
    #               max(t.words) AS transcript
    #     FROM      candidate  c, 
    #               transcript_array t,
    #               lattices s
    #     WHERE     t.lattice_id = c.lattice_id
    #       AND     t.lattice_id = s.lattice_id
    #     GROUP BY  c.lattice_id;
    #   """ # small dataset...
    #   # udf: ${APP_HOME}"/udf/ext_supervision.py"
    #   udf: ${APP_HOME}"/udf/label_candidate.py"
    #   output_relation: "candidate_label"
    #   before: ${APP_HOME}"/udf/before/clear_table.sh candidate_label"
    # }

    ############# TSV ###########
    ext_supervision {
      dependencies: ["ext_sample", "ext_runall"]
      style: "tsv_extractor"
      input: """
        SELECT    c.lattice_id AS lattice_id,
                  ARRAY_TO_STRING(ARRAY_AGG(c.starts ORDER BY starts, ends) , ',' )AS starts,
                  ARRAY_TO_STRING(ARRAY_AGG(c.ends   ORDER BY starts, ends) , ',' )AS ends,
                  ARRAY_TO_STRING(ARRAY_AGG(c.word   ORDER BY starts, ends) , '~^~' )AS candidates,
                  ARRAY_TO_STRING(ARRAY_AGG(c.candidate_id ORDER BY starts, ends) , ',' )AS candidate_ids,
                  ARRAY_TO_STRING(max(t.words) , '~^~') AS transcript
        FROM      candidate  c, 
                  transcript_array t,
                  lattices s
        WHERE     t.lattice_id = c.lattice_id
          AND     t.lattice_id = s.lattice_id
        GROUP BY  c.lattice_id;
      """ # small dataset...
      udf: pypy ${APP_HOME}"/udf/ext_supervision_tsv.py"
      # udf: util/extractor_input_writer.py /tmp/deepspeech-sample-supervision.tsv
      output_relation: "candidate_label"
      before: ${APP_HOME}"/udf/before/clear_table.sh candidate_label"
      parallelism: ${PARALLELISM}
      input_batch_size: 1000
    }

    ext_use_supervision {
      dependencies: ["ext_supervision"]
      style: "sql_extractor"
      sql: """
        UPDATE  candidate
        SET     is_true = l.is_true
        FROM    candidate_label AS l
        WHERE   candidate.lattice_id = l.lattice_id
        AND     candidate.candidate_id = l.candidate_id;
      """
    }

    ext_cand_2gram {
      dependencies: ["ext_sample", "ext_runall"] # not necessary, debug
      style: "plpy_extractor"
      input: """
        SELECT    lattice_id,
                  ARRAY_AGG(starts ORDER BY starts, ends)  AS starts,
                  ARRAY_AGG(ends   ORDER BY starts, ends)  AS ends,
                  ARRAY_AGG(word   ORDER BY starts, ends)  AS arr_feature,
                  ARRAY_AGG(candidate_id ORDER BY starts, ends) AS candidate_ids,
                  2 as gram_len
        FROM      candidate
        GROUP BY  lattice_id;
      """
      udf: ${APP_HOME}"/udf/ext_ngram.py"
      output_relation: "f_cand_2gram"
      before: ${APP_HOME}"/udf/before/clear_table.sh f_cand_2gram"
    }


  }

  # ###############
  # Inference Rules
  # ###############
  inference.factors {

    rule_cand_1gram {
      input_query: """
          SELECT  candidate.id as "candidate.id",
                  candidate.is_true as "candidate.is_true",
                  log(count)::int as logcount
          FROM    candidate,
                  google_1gram_reduced ggl,
                  lattices s
          WHERE   upper(word)         = upper(ggl.gram)
            AND   word not like '~SIL'
            AND   word != '<s>'
            AND   word != '</s>'
            AND   s.lattice_id = candidate.lattice_id
          """
      function: "IsTrue(candidate.is_true)"
      weight: "?(logcount)"
    }
    rule_cand_1gram_nonexist {
      input_query: """
          SELECT  candidate.id as "candidate.id",
                  candidate.is_true as "candidate.is_true"
          FROM    candidate, lattices s
          WHERE   s.lattice_id = candidate.lattice_id
            AND   NOT EXISTS (
                  SELECT  * 
                  FROM    google_1gram_reduced ggl
                  WHERE   upper(ggl.gram) = upper(word)
            )
            AND   word not like '~SIL%'
            AND   word != '<s>'
            AND   word != '</s>'
          """
      function: "IsTrue(candidate.is_true)"
      weight: "?"
    }
    rule_cand_2gram {
      input_query: """
          SELECT  candidate.id as "candidate.id",
                  candidate.is_true as "candidate.is_true",
                  log(count)::int as logcount
          FROM    f_cand_2gram f, 
                  candidate,
                  google_2gram_reduced ggl,
                  lattices s
          WHERE   candidate.lattice_id    = f.lattice_id
            AND   s.lattice_id = f.lattice_id
            AND   candidate.candidate_id  = f.candidate_id
            AND   upper(ggl.gram)         = upper(f.ngram)
            AND   ngram not like '%~SIL%'
            AND   ngram not like '<s>%'
            AND   ngram not like '%</s>'
          """
      function: "IsTrue(candidate.is_true)"
      weight: "?(logcount)"
    }

    rule_cand_2gram_nonexist {
      input_query: """
          SELECT  candidate.id as "candidate.id",
                  candidate.is_true as "candidate.is_true"
          FROM    f_cand_2gram f, 
                  candidate,
                  lattices s
          WHERE   candidate.lattice_id    = f.lattice_id
            AND   s.lattice_id = f.lattice_id
            AND   candidate.candidate_id  = f.candidate_id
            AND   NOT EXISTS (
                  SELECT  * 
                  FROM    google_2gram_reduced ggl
                  WHERE   upper(ggl.gram) = upper(f.ngram)
            )
            AND   ngram not like '%~SIL%'
            AND   ngram not like '<s>%'
            AND   ngram not like '%</s>'
          """
      function: "IsTrue(candidate.is_true)"
      weight: "?"
    }

    # "Confirm" feature
    rule_confirm {
      input_query: """
          SELECT  id as "candidate.id",
                  is_true as "candidate.is_true",
                  confirm as "confirm"
          FROM    candidate, lattices s
          WHERE   candidate.lattice_id = s.lattice_id
          """
      function: "IsTrue(candidate.is_true)"
      weight: "?(confirm)"
    }

    ### silence all have confirm=0
    # rule_silence {
    #   input_query: """
    #       SELECT  id as "candidate.id",
    #               is_true as "candidate.is_true"
    #       FROM    candidate, lattices s
    #       WHERE   candidate.lattice_id = s.lattice_id
    #         AND   word = '~SIL'
    #       """
    #   function: "IsTrue(candidate.is_true)"
    #   weight: "?"
    # }
    rule_startend {
      input_query: """
          SELECT  id as "candidate.id",
                  is_true as "candidate.is_true"
          FROM    candidate, lattices s
          WHERE   candidate.lattice_id = s.lattice_id
            AND   (word = '<s>' or word = '</s>')
          """
      function: "IsTrue(candidate.is_true)"
      weight: "?"
    }
    # TODO Handle silence!!!
    # TODO allneg, etc
    # TODO try combination of weights?
  }

}

